{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOa5mYxzfQelab+lYJ9ZRNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harishvicky-23/GEN-AI/blob/main/(Project)_Novel_Creator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2-j1dcvLt4a"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate safetensors\n",
        "!pip install --upgrade Pillow requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, KDPM2AncestralDiscreteScheduler, AutoencoderKL\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ðŸ”‘ OpenRouter API key\n",
        "API_KEY = \"\"  # <-- Replace this\n",
        "\n",
        "# ðŸš€ Load VAE and anime model\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    \"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"enhanceaiteam/AnimeSAI\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.to('cuda')\n",
        "\n",
        "# ðŸ“˜ Story generation using OpenRouter\n",
        "def generate_page(prompt, page_number):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"openai/gpt-3.5-turbo\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative story writer. Write vivid and emotional stories with strong character development.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Write page {page_number} of a 10-page story (around 1000 words) based on: '{prompt}'.\"}\n",
        "        ],\n",
        "        \"temperature\": 0.9,\n",
        "        \"max_tokens\": 1300\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
        "        result = response.json()\n",
        "        if 'choices' not in result:\n",
        "            print(f\"âŒ Error on page {page_number}:\\n{json.dumps(result, indent=2)}\")\n",
        "            return f\"[Error generating page {page_number}]\"\n",
        "        return result['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        print(f\"Exception: {e}\")\n",
        "        return f\"[Exception generating page {page_number}]\"\n",
        "\n",
        "def generate_story(prompt, title=\"My Story\"):\n",
        "    story = []\n",
        "    print(f\"\\nðŸ“– Generating story: {title}\")\n",
        "    for i in range(1, 11):\n",
        "        print(f\"âœï¸ Generating page {i}...\")\n",
        "        page = generate_page(prompt, i)\n",
        "        story.append(f\"\\n--- Page {i} ---\\n{page}\")\n",
        "        time.sleep(1)\n",
        "\n",
        "    filename = f\"{title.replace(' ', '_').lower()}.txt\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(story))\n",
        "    print(f\"\\nâœ… Story saved as: {filename}\")\n",
        "\n",
        "def generate_image(prompt, title):\n",
        "    print(\"\\nðŸ–¼ï¸ Generating cover image...\")\n",
        "    image = pipe(\n",
        "        prompt,\n",
        "        negative_prompt=\"low quality, blurry\",\n",
        "        width=1024,\n",
        "        height=1024,\n",
        "        guidance_scale=7,\n",
        "        num_inference_steps=50,\n",
        "        clip_skip=2\n",
        "    ).images[0]\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    # Center the title at bottom\n",
        "    bbox = draw.textbbox((0, 0), title, font=font)\n",
        "    text_width = bbox[2] - bbox[0]\n",
        "    text_height = bbox[3] - bbox[1]\n",
        "    W, H = image.size\n",
        "\n",
        "    draw.text(\n",
        "        ((W - text_width) / 2, H - text_height - 20),\n",
        "        title,\n",
        "        fill=\"white\",\n",
        "        font=font\n",
        "    )\n",
        "\n",
        "    filename = f\"{title.replace(' ', '_').lower()}.png\"\n",
        "    image.save(filename)\n",
        "    print(f\"âœ… Cover image saved as: {filename}\")\n",
        "\n",
        "# ðŸ§  MAIN FLOW\n",
        "if __name__ == \"__main__\":\n",
        "    story_prompt = input(\"ðŸ“¥ Enter your story idea (1 line): \")\n",
        "    story_title = input(\"ðŸŽ¨ Enter a title for your story: \")\n",
        "    generate_image(story_prompt, story_title)\n",
        "    generate_story(story_prompt, story_title)\n"
      ],
      "metadata": {
        "id": "xCT9uuVdLxDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XgwSYHvsMQgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}